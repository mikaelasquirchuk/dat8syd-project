{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import lxml.html as lh\n",
    "import os.path\n",
    "import urllib.request as urllib\n",
    "import zipfile as zp\n",
    "import glob\n",
    "import operator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gdelt_base_url = 'http://data.gdeltproject.org/events/'\n",
    "\n",
    "# get the list of all the links on the gdelt file page\n",
    "page = rq.get(gdelt_base_url+'index.html')\n",
    "doc = lh.fromstring(page.content)\n",
    "link_list = doc.xpath(\"//*/ul/li/a/@href\")\n",
    "\n",
    "# separate out those links that begin with four digits \n",
    "file_list = [x for x in link_list if str.isdigit(x[0:4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "infilecounter = 0\n",
    "outfilecounter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20170523.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170522.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170521.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170520.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170519.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170518.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170517.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170516.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170515.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170514.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170513.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170512.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170511.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170510.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170509.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n",
      "done\n",
      "20170508.export.CSV.zip\n",
      "downloading,\n",
      "extracting,\n",
      "parsing,\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-bfd4b6b1225a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# open the infile and outfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0;31m# extract lines with our interest country code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mfips_country_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitemgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m37\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m44\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "local_path = '/Users/production/documents/github/dat8syd-project/GDELT'\n",
    "\n",
    "fips_country_code = 'UK'\n",
    "\n",
    "for compressed_file in file_list[infilecounter:]:\n",
    "    print(compressed_file),\n",
    "    \n",
    "    # if we dont have the compressed file stored locally, go get it. Keep trying if necessary.\n",
    "    while not os.path.isfile(local_path+compressed_file): \n",
    "        print('downloading,'),\n",
    "        urllib.urlretrieve(url=gdelt_base_url+compressed_file, \n",
    "                           filename=local_path+compressed_file)\n",
    "        \n",
    "    # extract the contents of the compressed file to a temporary directory    \n",
    "    print('extracting,'),\n",
    "    z = zp.ZipFile(file=local_path+compressed_file, mode='r')    \n",
    "    z.extractall(path=local_path+'tmp/')\n",
    "    \n",
    "    # parse each of the csv files in the working directory, \n",
    "    print('parsing,'),\n",
    "    for infile_name in glob.glob(local_path+'tmp/*'):\n",
    "        outfile_name = local_path+'country/'+fips_country_code+'%04i.tsv'%outfilecounter\n",
    "        \n",
    "        # open the infile and outfile\n",
    "        with open(infile_name, mode='r') as infile, open(outfile_name, mode='w') as outfile:\n",
    "            for line in infile:\n",
    "                # extract lines with our interest country code\n",
    "                if fips_country_code in operator.itemgetter(51, 37, 44)(line.split('\\t')):    \n",
    "                    outfile.write(line)\n",
    "            outfilecounter +=1\n",
    "            \n",
    "        # delete the temporary file\n",
    "        os.remove(infile_name)\n",
    "    infilecounter +=1\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0000.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0001.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0002.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0003.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0004.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0005.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0006.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0007.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0008.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0009.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0010.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0011.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0012.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0013.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0014.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0015.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0016.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0017.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0018.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0019.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0020.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0021.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0022.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0023.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0024.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0025.tsv\n",
      "/Users/production/documents/github/dat8syd-project/GDELTcountry/UK0026.tsv\n"
     ]
    }
   ],
   "source": [
    "# Get the GDELT field names from a helper file\n",
    "colnames = pd.read_excel('CSV.header.fieldids.xlsx', sheetname='Sheet1', \n",
    "                         index_col='Column ID', parse_cols=1)['Field Name']\n",
    "\n",
    "# Build DataFrames from each of the intermediary files\n",
    "files = glob.glob(local_path+'country/'+fips_country_code+'*')\n",
    "DFlist = []\n",
    "for active_file in files:\n",
    "    print(active_file)\n",
    "    DFlist.append(pd.read_csv(active_file, sep='\\t', header=None, dtype=str,\n",
    "                              names=colnames, index_col=['GLOBALEVENTID']))\n",
    "\n",
    "# Merge the file-based dataframes and save a pickle\n",
    "DF = pd.concat(DFlist)\n",
    "DF.to_pickle(local_path+'backup'+fips_country_code+'.pickle')    \n",
    "    \n",
    "# once everythin is safely stored away, remove the temporary files\n",
    "for active_file in files:\n",
    "    os.remove(active_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
