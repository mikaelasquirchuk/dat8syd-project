<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<title>Cancellations</title>
		<!-- Reveal CSS -->
		<link rel="stylesheet" href="css/reveal.css">
		<!-- Theme used from Reveal JS-->
		<link rel="stylesheet" href="css/theme/black.css">
		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">
		<!--Font import-->
		<link href="https://fonts.googleapis.com/css?family=Oswald" rel="stylesheet">
		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>
	</head>
	<body>
		<div class="reveal">
			<div class="slides">
				<section data-background-color="black">
					<img id="cog" src="assets/img/cog.png">
					<h1>Cancellations at<br>
						General Assembly</h1>
				</section>
				<section>
					<section data-background-image="assets/img/flamingos.gif">
						<h1>THE PROBLEM</h1>
					</section>
					<section>
						<div style="float:left; width:65%">
							<h2 style="margin-top:50px">Business Understanding</h2>
							<h4 style="margin-top:50px">Enrolments either (1) cancel or (2) become students.</h4>
							<p class="emphasis" style="margin-top:50px">Some  enrolments never start their course. Around 17.82% of all enrolments cancel before their first day.</p>
							<p class="emphasis">This causes loss of income, difficulty in forecasting and wasted resourcing.</p>
						</div>
						<img id="flowchart" src="assets/img/flow.png" style="float:right"/>
					</section>
					<section>
						<h2>END GOALS:</h2>
						<h4>1. Know them</h4>
						<div class="emphasis" style="margin-bottom:20px">Accurately predict whether a student will cancel from their course.</div>
						<h4>2. Stop them</h4>
						<div class="emphasis" >Explore any actionable insights in preventing cancellations.</div>
					</section>
				</section>
				<section>
					<section data-background-image="assets/img/rubixcube.gif">
						<h1>THE SOLUTION</h1>
					</section>
					<section>
						<h3>1. KNOW THEM</h3>
						<h5>Random Forest with balanced data</h5>
						<p style="text-align:left"> I found a model which had a better than 50% accurately of correctly predicting a cancellation, through balancing the dataset and then running random forest. </p>
						<div class="coding" style="float:left;width:50%">
							rfclf.oob_score_
						</div>
						<div class="output" style="margin-top:10px; width:45%;float:right">
							0.58318061494603946
						</div>
						<div style="clear:both;width:100%">
							<div class="output" style="float:left; width:50%">
									Accuracy Score: 0.579108124618<br>
									Confusion Matrix: <br>
									[[364 462]<br>
									 [227 584]]<br>
									Sensitivity: 0.440677966102<br>
									Specificity: 0.72009864365
								</div>
								<div class="output" style="float:right; width:45%">
								<img src="assets/img/randomforest3confusionmatrix.png" style="float:left; width:60%"/>
								</div>
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:50%">
								preds = rfclf.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()
							</div>
							<div class="output" style="text-align:center; float:right; width:45%">
								<img src="assets/img/randomforest3-rocauc.png" style="width:80%;float:left"/>
							</div>
						</div>
					</section>
					<section>
						<h2>2. STOP THEM</h2>
						<h5 style="text-align:left">There were some key insights that came to light during the project, including: </h5>
						<p style="text-align:left">There is no clear indicator of a cancellation - there's no easy fix.</p>
						<p style="text-align:left">There is some indication that the following have an effect of cancellation:
							<ul>
								<li>Lead source - where do they come from?</li>
								<li>Expected payment method - how do we expect them to pay?</li>
							</ul>
						</p>
						<p style="text-align:left">Some good news: Sydney has a lower cancellation rate than other metros.</p>
					</section>
				</section>
				<section>
					<section data-background-image="assets/img/matrixdata.gif">
						<h1>THE PROCESS</h1>
					</section>
					<section>
						<h1>THE PROCESS</h1>
						<div>
							<h6>STEP 1: EXPORT</h6>
							<h6>STEP 2: DATA UNDERSTANDING</h6>
							<h6>STEP 3: DATA PREPARATION</h6>
							<h6>STEP 4: MODELING</h6>
							<h6>STEP 5: EVALUATION</h6>
						</div>
					</section>
					<section>
						<h1>THE PROCESS</h1>
						<div >
							<h6>STEP 6: REPEAT STEPS 3-5</h6>
							<h6>STEP 7: AND AGAIN</h6>
							<h6>STEP 8: AND AGAIN</h6>
							<h6>STEP 9: AND AGAIN</h6>
							<h6>STEP 10: DEPLOY</h6>
						</div>
					</section>
					<section>
						<h2>DATA UNDERSTANDING</h2>
						<h3>EXPORTING THE DATA</h3>
						<p>Export the data from Looker and download it as a CSV, then read it into Python.</p>
						<div class="coding">enrolments = pd.read_csv("data/courses snap_sales_funnel 2017-07-05T1254.csv", low_memory=False)</div>
						<div style="width:100%; text-align:left; padding-top:30px">
							<ul>
								<li>Metro - which city were they enrolled in?</li>
								<li>Expected Payment - how did we expect them to pay?</li>
								<li>Application Type - how did they apply?</li>
								<li>Pardot Category - how did they find General Assembly?</li>
							</ul>
						</div>
						<h3>EXTRAPOLATING THE DATA</h3>
						<div class="coding">enrolments['Cancelled'] = enrolments.CanceledDate.notnull()<br>
							enrolments['APAC'] = enrolments['Metro'].isin(['sydney','melbourne','hong-kong','singapore','brisbane'])</div>
					</section>
					<section>
						<h3>VISUALISING THE DATA</h3>
						<h5 style="margin:0px">Cancellations by month</h5>
						<p>Although enrolment numbers are down, cancellations are steady:</p>
						<img src="assets/img/cancellations-by-month.png"/>
					</section>
					<section>
						<h5 style="margin:0px">Cancellations by metro</h5>
						<p>Sydney actually has a lower rate of cancellations than other metros:</p>
						<img src="assets/img/cancellations-by-metro.png"/>
					</section>
					<section>
						<h5 style="margin:0px">Payment methods</h5>
						<p>Students who are paying by private loan or on their own pocket are more likely to cancel than employer-paid:</p>
						<img src="assets/img/cancellations-by-pay-method.png"/>
					</section>
					<section>
						<h5 style="margin:0px">Cancellations by lead source</h5>
						<p>There's some lead sources that have a higher rate of cancellations:</p>
						<img src="assets/img/cancellations-by-pardotcategory.png"/>
					</section>
					<section>
						<h5 style="margin:0px">Cancellations by application type</h5>
						<p>No application type has a higher rate of cancellation:</p>
						<img src="assets/img/cancellations-by-applicationtype.png"/>
					</section>
					<section>
						<h2>DATA PREPARATION</h2>
						<h5>COMPLETING THE DATA</h5>
						<!--<p>A lot of the missing data was cleared just by limiting the data to post mid-2014 and pre mid-2017.</p>-->
						<div class="coding">enrolments = enrolments[enrolments.EnrolDate > 20140630]<br>
							enrolments = enrolments[enrolments.EnrolDate < 20170630]</div>
						<!--<p>Other null values were relatively easy to fix using the mean or simply entering "Unknown" for categorical variables.</p>-->
						<div class="coding">enrolments.DaysEnroltoStart.fillna(enrolments.DaysEnroltoStart.mean(), inplace=True)<br>
							enrolments.ExpectedPayment.fillna("Unknown", inplace=True)</div>
						<h5>STREAMLINING THE DATA</h5>
						<!--<p>Some variables had ad hoc entries as well as clear categories.</p>-->
						<div class="coding">commonapptypes = enrolments.ApplicationType.value_counts().index[enrolments.ApplicationType. value_counts()>100]<br>
							enrolments = enrolments[enrolments.ApplicationType.isin(commonapptypes)]</div>
						<h5>DUMMYING THE DATA</h5>
						<!--<p>Some algorithms only accept numerical or boolean inputs, so the categorical data had to be 'dummied up'. </p>-->
						<div class="coding">dummydata = pd.get_dummies(data=enrolments, columns = ['Metro','Course','Type','ExpectedPayment','ApplicationType','PardotCategory','EnrolDay'], prefix = ['Metro','Course','Type','ExpectedPayment','ApplicationType','PardotCategory','EnrolDay'] )<br>dummydata.shape</div>
						<div class="output">
							30293, 100
						</div>
					</section>
					<section>
						<h2>MODELING</h2>
						<h3>CHOOSING THE MODEL</h3>
						<p><em>Classification problem</em>: Students either cancel or don't cancel.</p>
						<p><em>Unbalanced data</em>: Cancelled students only accounted for 17% of the data; even a random pick will predict a non-cancelled student correctly 83% of the time.</p>
					</section>
					<section>
						<h2>EVALUATION</h2>
						<p> Method needs to be: uniform and based how we want to use the model.</p>
						<p> Cancellation is like medical diagnosis - we care more about false negatives (i.e. predicted not cancelled and then they cancel); we don't care that much about false positives (i.e. predicted cancelled and then they don't cancel).  </p>
						<p> Comparing models using: Confusion Matrix, Specificity, Sensitivity, AUC ROC. </p>
					</section>
					<section>
						<h5>Baseline</h5>
						<div class="coding" style="clear:both;width:100%">
							from sklearn.dummy import DummyClassifier<br>
							dumb = DummyClassifier(strategy='most_frequent')<br>
							dumb.fit(X_train, y_train)<br>
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:50%">
								y_dumb_class = dumb.predict(X_test)<br>
								print ('Accuracy Score: ', metrics.accuracy_score(y_test, y_dumb_class))<br>
								print('Confusion Matrix: ', metrics.confusion_matrix(y_test, y_dumb_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))
							</div>
							<div class="output" style="float:right; width:45%">
								<div style="float:left; width:50%">
									Accuracy Score: 0.890151515152<br>
									Confusion Matrix: <br>
									[[6815    0]<br>
								 	[ 841    0]]<br>
									Sensitivity: 1.0<br>
									Specificity: 0.0
								</div>
								<img src="assets/img/baselineconfusionmatrix.png" style="float:right; width:50%"/>
							</div>
						</div>
						<div style="clear:both;width:100%">
							<div class="output" style="float:right; width:45%">
								<img src="assets/img/baseline-rocauc.png" style=" width:80%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								import matplotlib.pyplot as plt<br>
								preds = dumb.predict_proba(X_test)[:,1]<br>
								fpr, tpr, _ = metrics.roc_curve(y_test, preds)<br>
								roc_auc = metrics.auc(fpr,tpr)<br>
								plt.figure()<br>
								lw = 2<br>
								plt.plot(fpr, tpr, color='red',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)<br>
								plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')<br>
								plt.xlim([0.0, 1.0])<br>
								plt.ylim([0.0, 1.05])<br>
								plt.xlabel('False Positive Rate')<br>
								plt.ylabel('True Positive Rate')<br>
								plt.title('Receiver operating characteristic example')<br>
								plt.legend(loc="lower right")<br>
								plt.show()<br>
							</div>
						</div>
					</section>
					<section>
						<h5>Decision Tree</h5>
						<div class="coding" style="clear:both;width:100%">
							from sklearn import tree<br>
							ctree = tree.DecisionTreeClassifier(random_state=1, max_depth=3)<br>
							ctree.fit(X_train, y_train)<br>
						</div>
						<div style="clear:both">
							<img src="assets/img/decisiontree-enrolments.png" height="300px"/>
						</div>
					</section>
					<section>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:50%">
								y_pred_class = ctree.predict(X_test)<br>
								print('Accuracy Score:', metrics.accuracy_score(y_test, y_pred_class))<br>
								print('Confusion Matrix:', metrics.confusion_matrix(y_test, y_pred_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))<br>
							</div>
							<div class="output" style="float:right; width:45%">
								<div style="float:left; width:50%">
									Accuracy Score: 0.890151515152<br>
									Confusion Matrix: <br>
									[[6815    0]<br>
									 [ 841    0]]<br>
									Sensitivity: 1.0<br>
									Specificity: 0.0
								</div>
								<img src="assets/img/baselineconfusionmatrix.png" style="float:right; width:50%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								preds = ctree.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()<br>
							</div>
							<div class="output" style="float:right; width:45%">
								<img src="assets/img/decision-tree-rocauc.png" style=" width:80%"/>
							</div>
						</div>
					</section>
					<section>
						<h5>Logistic Regression</h5>
						<div class="coding" style="clear:both;width:100%;margin-bottom:0px!important">
							from sklearn.linear_model import LogisticRegression<br>
							logreg = LogisticRegression()<br>
							logreg.fit(X_train, y_train)<br>
							zip(all_ftcolumns, logreg.coef_[0])<br>
							print(logreg.fit(X_train, y_train))<br>
						</div>
						<div class="output" style="clear:both;width:100%;margin-top:10px">
							LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True, intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1, penalty='l2', random_state=None, solver='liblinear', tol=0.0001, verbose=0, warm_start=False)<br>
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:50%">
								y_pred_class = logreg.predict(X_test)<br>
								print('Accuracy Score:', metrics.accuracy_score(y_test,y_pred_class))<br>
								print('Confusion Matrix:', metrics.confusion_matrix(y_test, y_pred_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))
							</div>
							<div class="output" style="float:right; width:45%">
								<div style="float:left; width:50%">
									Accuracy Score: 0.890151515152<br>
									Confusion Matrix: [[6815    0]<br>
									 [ 841    0]]<br>
									Sensitivity: 1.0<br>
									Specificity: 0.0
								</div>
								<img src="assets/img/logregconfusinomatrix.png" style="float:right; width:50%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								preds = dumb.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()
							</div>
							<div class="output" style="float:right; width:45%">
								<img src="assets/img/logreg-rocauc.png" style=" width:80%"/>
							</div>
						</div>
					</section>
					<section>
						<h5>KNN Classifier</h5>
						<div class="coding" style="clear:both; width:100%">
							from sklearn.neighbors import KNeighborsClassifier<br>
							KNN_model = KNeighborsClassifier(5)<br>
							KNN_model.fit(X_train, y_train)<br>
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:55%">
								y_pred_class = KNN_model.predict(X_test)<br>print('Accuracy Score:', metrics.accuracy_score(y_test,y_pred_class))<br>
								print('Confusion Matrix:', metrics.confusion_matrix(y_test, y_pred_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))<br>
							</div>
							<div class="output" style="float:right; width:40%">
								<div style="float:left; width:50%">
									Accuracy Score: 0.879440961338<br>
									Confusion Matrix: <br>
									[[6719   96]<br>
									 [ 827   14]]<br>
									Sensitivity: 0.985913426266<br>
									Specificity: 0.0166468489893
								</div>
								<img src="assets/img/knnconfusionmatrix.png" style="float:right; width:50%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								preds = KNN_model.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()<br>
							</div>
							<div class="output" style="text-align:center; float:right; width:45%">
								<img src="assets/img/knnclass-rocauc.png" style=" width:80%"/>
							</div>
						</div>
					</section>
					<section>
						<h5>Random Forest</h5>
						<div class="coding" style="clear:both;width:100%">
							from sklearn.ensemble import RandomForestClassifier<br>
							rfclf = RandomForestClassifier(n_estimators=400, max_features=2, oob_score=True, random_state=1,class_weight='balanced')<br>
							rfclf.fit(dummydata[all_ftcolumns], dummydata.Cancelled)<br>
							rfclf.oob_score_
						</div>
						<div class="output" style="clear:both;width:100%;margin-top:10px">
							0.89305074782835869
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:55%">
								y_pred_class = rfclf.predict(X)<br>
								print('Accuracy Score:', metrics.accuracy_score(y,y_pred_class))<br>
								print('Confusion Matrix:',metrics.confusion_matrix(y, y_pred_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))
							</div>
							<div class="output" style="float:right; width:40%">
								<div style="float:left; width:50%">
									Accuracy Score: 1.0<br>
									Confusion Matrix: <br>
									[[6815    0]<br>
									 [   0  841]]<br>
									Sensitivity: 1.0<br>
									Specificity: 1.0<br>
								</div>
								<img src="assets/img/randomforest1confusionmatrix.png" style="float:right; width:50%"/>
							</div>
						</div>
						<div style="clear:both;width:100%">
							<div class="output" style="text-align:center; float:right; width:45%">
								<img src="assets/img/randomforest1-rocauc.png" style=" width:80%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								preds = rfclf.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()
							</div>
						</div>
					</section>
					<section data-background-image="assets/img/noooo.gif">
						<h1>It's overfit...</h1>
					</section>
					<section>
						<h5>Random Forest with Train/Test Split (not overfit)</h5>
						<div class="coding" style="clear:both;width:100%">
							from sklearn.ensemble import RandomForestClassifier<br>
							rfclf = RandomForestClassifier(n_estimators=400, max_features=2, oob_score=True, random_state=1,class_weight='balanced')<br>
							rfclf.fit(X_train,y_train)<br>
							rfclf.oob_score_
						</div>
						<div class="output" style="clear:both;width:100%;margin-top:10px">
							0.89406078550901336
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:55%">
								y_pred_class = rfclf.predict(X_test)<br>
								print('Accuracy Score:', metrics.accuracy_score(y_test,y_pred_class))<br>
								print('Confusion Matrix:',metrics.confusion_matrix(y_test, y_pred_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))
							</div>
							<div class="output" style="float:right; width:40%">
								<div style="float:left; width:50%">
									Accuracy Score: 0.889629049112<br>
									Confusion Matrix: <br>
									[[6809    6]<br>
 									 [ 839    2]]<br>
									Sensitivity: 0.999119589142<br>
									Specificity: 0.00237812128419
								</div>
								<img src="assets/img/randomforest2confusionmatrix.png" style="float:right; width:50%"/>
							</div>
						</div>
						<div style="clear:both;width:100%">
							<div class="output" style="text-align:center; float:right; width:45%">
								<img src="assets/img/randomforest2-rocauc.png" style=" width:80%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								preds = rfclf.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()
							</div>
						</div>
					</section>
					<section>
						<h3>BALANCING THE DATA</h3>
						<h3>WITH A LITTLE HELP FROM GEOFF</h3>
						<div class="coding" style="float:left; width:50% !important">
							enrolments.Cancelled.value_counts()
						</div>
						<div class="output" style="float:right; width:45%">
							False    27348<br>
							True      3274
						</div>
						<div class="coding" style="float:left; width:100% !important">
							sample_size = sum(dummydata.Cancelled == 1)<br>
							NoCancelled_indices = dummydata[dummydata.Cancelled == 0].index<br>
							Cancelled_indices = dummydata[dummydata.Cancelled == 1].index<br>
							sample_indices = np.random.choice(NoCancelled_indices, sample_size, replace = False)<br>
							SampleandCancelled_indices = pd.Index(sample_indices).union(Cancelled_indices) <br>
							Cancelled_Sample= dummydata.loc[sample_indices]<br>
							Cancelled_Remainder = dummydata.loc[~dummydata.index.isin(SampleandCancelled_indices)]<br>
							frames = [dummydata[dummydata.Cancelled == 1],Cancelled_Sample]<br>
							balanced = pd.concat(frames)
						</div>
						<div class="coding" style="float:left; width:50% !important">
							balanced.Cancelled.value_counts()
						</div>
						<div class="output" style="float:right; width:45%">
							True     3274<br>
							False    3274
						</div>
						<div class="coding" style="clear:both; width:100% !important">
							X = balanced[all_ftcolumns]<br>
							y = balanced.Cancelled
						</div>
					</section>
					<section>
						<h5>Random Forest with balanced data</h5>
						<div class="coding" style="clear:both;width:100%">
							from sklearn.cross_validation import train_test_split<br>
							X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)<br>
							from sklearn.ensemble import RandomForestClassifier<br>
							rfclf = RandomForestClassifier(n_estimators=400, max_features=2, oob_score=True, random_state=1, class_weight='balanced', max_depth=3)<br>
							rfclf.fit(X_train,y_train)<br>
							rfclf.oob_score_
						</div>
						<div class="output" style="clear:both;width:100%;margin-top:10px">
							0.58318061494603946
						</div>
						<div style="clear:both;width:100%">
							<div class="coding" style="float:left; width:55%">
								y_pred_class = rfclf.predict(X_test)<br>
								print('Accuracy Score:', metrics.accuracy_score(y_test,y_pred_class))<br>
								print('Confusion Matrix:',metrics.confusion_matrix(y_test, y_pred_class))<br>
								print('Sensitivity:',(confusion_matrix[0,0]/(confusion_matrix[0,1]+ confusion_matrix[0,0])))<br>
								print('Specificity:',(confusion_matrix[1,1]/(confusion_matrix[1,1]+ confusion_matrix[1,0])))
							</div>
							<div class="output" style="float:right; width:40%">
								<div style="float:left; width:50%">
									Accuracy Score: 0.579108124618<br>
									Confusion Matrix: <br>
									[[364 462]<br>
									 [227 584]]<br>
									Sensitivity: 0.440677966102<br>
									Specificity: 0.72009864365
								</div>
								<img src="assets/img/randomforest3confusionmatrix.png" style="float:right; width:50%"/>
							</div>
						</div>
						<div style="clear:both;width:100%">
							<div class="output" style="text-align:center; float:right; width:45%">
								<img src="assets/img/randomforest3-rocauc.png" style=" width:80%"/>
							</div>
							<div class="coding" style="float:left; width:50%">
								preds = rfclf.predict_proba(X_test)[:,1]<br>
								...<br>
								plt.show()
							</div>
						</div>
					</section>
					<section>
						<div class="coding" style="clear:both; width:100% !important">
							preds = rfclf.predict_proba(X_test)[:,1]<br>
							...<br>
							plt.show()<br>
						</div>
						<div class="output" style="text-align:center">
							<img src="assets/img/randomforest3-rocauc.png" style=" width:80%"/>
						</div>
					</section>
					<section>
						<h3>CHECKING THE MODEL</h3>
						<div class="coding" style="float:left; width:30% !important; margin-top:10px">
							feature_importance = pd.DataFrame({'feature':all_ftcolumns, 'importance':rfclf.feature_importances_})<br>
							feature_importance.sort('importance',ascending=False)<br>
						</div>
						<div class="output" style="text-align:center;float:right; width:65%">
							<img src="assets/img/randomforest3-features-list.png" style="width:70%"/>
						</div>
					</section>
				</section>
				<section>
					<section data-background-image="assets/img/whatnext.gif">
						<h1>NEXT STEPS</h1>
					</section>
					<section>
						<h2>MAKE IT BETTER</h2>
					</section>
					<section>
						<h2>DEPLOYMENT</h2>
					</section>
				</section>
				<section  data-background-color="black">
					<img src="assets/img/thankyou.gif"/>
				</section>
			</div>
		</div>
		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>
		<script>
			Reveal.initialize({
				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>
	</body>
</html>
